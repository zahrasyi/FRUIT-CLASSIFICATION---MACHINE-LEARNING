{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12016513,"sourceType":"datasetVersion","datasetId":7560046}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zahrasyifaul/apple-vs-orange-classification-with-resnet18?scriptVersionId=245513643\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# APPLE N ORANGE CLASSIFICATION WITH RESNET18","metadata":{}},{"cell_type":"markdown","source":"# IMPORT LIBRARY","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:14.160234Z","iopub.execute_input":"2025-06-15T05:35:14.160806Z","iopub.status.idle":"2025-06-15T05:35:14.16463Z","shell.execute_reply.started":"2025-06-15T05:35:14.160784Z","shell.execute_reply":"2025-06-15T05:35:14.164038Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SETUP DAN TRANSFORMASI DATA","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = \"/kaggle/input/fruitdataset/archive/fruit-dataset\"\nprint(f\"Using device: {device}\")\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:14.16595Z","iopub.execute_input":"2025-06-15T05:35:14.1665Z","iopub.status.idle":"2025-06-15T05:35:14.181877Z","shell.execute_reply.started":"2025-06-15T05:35:14.166482Z","shell.execute_reply":"2025-06-15T05:35:14.181299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD DATASET DAN SPLIT","metadata":{}},{"cell_type":"code","source":"full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\nval_percent = 0.2\nval_size = int(len(full_dataset) * val_percent)\ntrain_size = len(full_dataset) - val_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\nval_dataset.dataset.transform = test_transform\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nclass_names = full_dataset.classes\nprint(\"Class names:\", 'apple ,','orange')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:14.182932Z","iopub.execute_input":"2025-06-15T05:35:14.183365Z","iopub.status.idle":"2025-06-15T05:35:14.603185Z","shell.execute_reply.started":"2025-06-15T05:35:14.183348Z","shell.execute_reply":"2025-06-15T05:35:14.602517Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VISUALISASI SAMPEL GAMBAR","metadata":{}},{"cell_type":"code","source":"def imshow(img, title):\n    img = img * 0.5 + 0.5\n    npimg = img.numpy()\n    plt.figure(figsize=(8, 4))\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(title)\n    plt.axis('off')\n    plt.show()\n\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\nimshow(torchvision.utils.make_grid(images[:8]), title=' | '.join([class_names[i] for i in labels[:8]]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:14.60444Z","iopub.execute_input":"2025-06-15T05:35:14.604717Z","iopub.status.idle":"2025-06-15T05:35:15.040484Z","shell.execute_reply.started":"2025-06-15T05:35:14.604698Z","shell.execute_reply":"2025-06-15T05:35:15.039498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD MODEL RESNET18","metadata":{}},{"cell_type":"code","source":"from torchvision.models import ResNet18_Weights\n\nmodel = models.resnet18(weights=ResNet18_Weights.DEFAULT)\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Linear(model.fc.in_features, 1)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:15.04255Z","iopub.execute_input":"2025-06-15T05:35:15.042793Z","iopub.status.idle":"2025-06-15T05:35:15.299565Z","shell.execute_reply.started":"2025-06-15T05:35:15.042764Z","shell.execute_reply":"2025-06-15T05:35:15.29901Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# earlystopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:15.301279Z","iopub.execute_input":"2025-06-15T05:35:15.301513Z","iopub.status.idle":"2025-06-15T05:35:15.306391Z","shell.execute_reply.started":"2025-06-15T05:35:15.301497Z","shell.execute_reply":"2025-06-15T05:35:15.305719Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TRAINING DAN EVALUASI","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Loss dan Optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n\n# EarlyStopping (pastikan kamu punya kelas EarlyStopping)\nearly_stopping = EarlyStopping(patience=3)\n\nnum_epochs = 15\ntrain_losses = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device).float().unsqueeze(1)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_loss = running_loss / len(train_loader)\n    train_losses.append(avg_loss)\n\n    # ⬇️ Validation loss (DIPINDAH KE DALAM LOOP)\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for val_images, val_labels in val_loader:\n            val_images = val_images.to(device)\n            val_labels = val_labels.to(device).float().unsqueeze(1)\n            val_outputs = model(val_images)\n            loss = criterion(val_outputs, val_labels)\n            val_loss += loss.item()\n    val_loss /= len(val_loader)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}\")\n\n    # ⬇️ Early stopping (MASUK LOOP)\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping triggered!\")\n        break\n\n\n\n# ✅ Confusion Matrix\nacc = accuracy_score(all_labels, all_preds)\ncm = confusion_matrix(all_labels, all_preds)\n\nprint(f\"\\nFinal Validation Accuracy: {acc*100:.2f}%\")\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Predicted label\")\nplt.ylabel(\"True label\")\nplt.title(\"Final Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:15.30701Z","iopub.execute_input":"2025-06-15T05:35:15.307207Z","iopub.status.idle":"2025-06-15T05:35:41.855695Z","shell.execute_reply.started":"2025-06-15T05:35:15.307193Z","shell.execute_reply":"2025-06-15T05:35:41.854917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VISUALISASI LOSS KONVERGEN","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', color='blue')\nplt.title(\"Loss Convergence over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Average Loss\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:41.856719Z","iopub.execute_input":"2025-06-15T05:35:41.857002Z","iopub.status.idle":"2025-06-15T05:35:42.014519Z","shell.execute_reply.started":"2025-06-15T05:35:41.856961Z","shell.execute_reply":"2025-06-15T05:35:42.0138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PENGUJIAN GAMBAR ","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\ndef predict_image(image_path, model, transform, class_names):\n    # Load image\n    image = Image.open(image_path).convert('RGB')\n    \n    # Apply same transform as test set\n    image = transform(image).unsqueeze(0).to(device)\n\n    # Set model to eval\n    model.eval()\n    with torch.no_grad():\n        output = model(image)\n        pred = torch.sigmoid(output).item()\n        label = 1 if pred > 0.5 else 0\n        confidence = pred if label == 1 else 1 - pred\n\n    print(f\"Predicted: {class_names[label]} (Confidence: {confidence*100:.2f}%)\")\n\n    # Show the image\n    img_show = image.squeeze().cpu() * 0.5 + 0.5  # unnormalize\n    npimg = img_show.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(f\"Prediction: {class_names[label]}\")\n    plt.axis('off')\n    plt.show()\n\n# Contoh penggunaan:\n# ganti '/kaggle/input/sampel/apple.jpg' dengan path gambar kamu\ntest_image_path = \"/kaggle/input/fruitdataset/archive/fruit-dataset/train/mangga.jpg\"\npredict_image(test_image_path, model, test_transform, class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:42.015292Z","iopub.execute_input":"2025-06-15T05:35:42.015544Z","iopub.status.idle":"2025-06-15T05:35:42.154751Z","shell.execute_reply.started":"2025-06-15T05:35:42.015527Z","shell.execute_reply":"2025-06-15T05:35:42.153955Z"}},"outputs":[],"execution_count":null}]}